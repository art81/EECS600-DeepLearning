{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EECS600_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnFbvwkcNoqq",
        "colab_type": "text"
      },
      "source": [
        "# Homework 3 - EECS 600 Deep Learning\n",
        "\n",
        "Name: Andrew Tarnoff\n",
        "\n",
        "Instructions: All assignments are to be completed individually. Please complete each question as best you can. Once you have completed all of the problems, reset your runtime or kernel and run the notebook in order. Download the .ipynb file and submit it via Canvas.\n",
        "\n",
        "Library usage: Several of the algorithms implemented in this, and other assignments, have implementations available in tensorflow. For this assignment, you may use any of the functionality within tensorflow.\n",
        "\n",
        "All code presented in class is free to use in your assignments.\n",
        "\n",
        "Your grade is based on the correctness of your implementation, not the quality of your code but you are encouraged to include comments in your code to help the graders understand your decisions.\n",
        "\n",
        "For clarity, the final operation you should take is restarting the runtime and running all.\n",
        "\n",
        "Due Date: 12/6/19 - midnight EST\n",
        "\n",
        "100 Points Total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElBYya4BNs_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import random\n",
        "\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Flatten,Input,Reshape\n",
        "\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy2kpBq8NxFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "train_images = (np.reshape(train_images, (len(train_images),28,28,1)).astype('float32') - 127.5) / 127.5\n",
        "test_images = (np.reshape(test_images, (len(test_images),28,28,1)).astype('float32') - 127.5) / 127.5\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EqfoQQmE-m9",
        "colab_type": "text"
      },
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "The train_images and train_labels arrays are the training setâ€”the data the model uses to learn.\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents:\n",
        "\n",
        "Label |\tClass\n",
        "------|------\n",
        "0 |\tT-shirt/top\n",
        "1 |\tTrouser\n",
        "2 |\tPullover\n",
        "3 |\tDress\n",
        "4 |\tCoat\n",
        "5 |\tSandal\n",
        "6 |\tShirt\n",
        "7 |\tSneaker\n",
        "8 |\tBag\n",
        "9 |\tAnkle boot\n",
        "\n",
        "Each image is mapped to a single label. Since the class names are not included with the dataset.\n",
        "\n",
        "More information and a working example using this dataset here: https://www.tensorflow.org/tutorials/keras/classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adcmfAIFT7o3",
        "colab_type": "text"
      },
      "source": [
        "## Recommendation\n",
        "When building and testing your code, work on a smaller subset of the data. [This example](https://stackoverflow.com/questions/14262654/numpy-get-random-set-of-rows-from-2d-array) may help in that.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_udcy0TEQ_pK",
        "colab_type": "text"
      },
      "source": [
        "# Question 1\n",
        "Implement a Deep Convolutional Generative Adversarial Network for generating fasion MNIST photos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-AJ_KpMO9r5",
        "colab_type": "code",
        "outputId": "2363f1bd-087f-4a87-f8d5-efb9bd25143f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "#(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "def plotImage(img):\n",
        "  figure, axes = plt.subplots(nrows=2, ncols=1)\n",
        "  figure.set_size_inches(5, 5)\n",
        "  \n",
        "  for idx, axis in enumerate(axes.flat):\n",
        "    reconstrImage = np.reshape(img, (28, 28))*127.5 + 127.5\n",
        "    \n",
        "    axis.imshow(reconstrImage, cmap=plt.cm.gray)\n",
        "    axis.set_frame_on(False)\n",
        "    axis.set_axis_off()\n",
        "\n",
        "def getRandomSampleFromDataset():\n",
        "  idx = random.choice(range(len(train_images)))\n",
        "  return train_images[idx, :]\n",
        "\n",
        "plotImage(getRandomSampleFromDataset())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-402488772bc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplotImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetRandomSampleFromDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-402488772bc8>\u001b[0m in \u001b[0;36mgetRandomSampleFromDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetRandomSampleFromDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZh2JzpHTgp8",
        "colab_type": "text"
      },
      "source": [
        "# DEFINING THE GENERATOR AND DIFFERENTIATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFUzpyqgTgD5",
        "colab_type": "code",
        "outputId": "8ba0f01c-cd14-4455-918f-9e8ff11bc9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential(name = 'Generator')\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (3, 3), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential(name = 'Discriminator')\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "#Test these\n",
        "generator = make_generator_model()\n",
        "print(generator.summary())\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "print(discriminator.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12544)             1254400   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         576       \n",
            "=================================================================\n",
            "Total params: 2,329,920\n",
            "Trainable params: 2,304,448\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6273      \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DoICZjEwxbB",
        "colab_type": "text"
      },
      "source": [
        "Test These Models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXAVxIxWwwpR",
        "colab_type": "code",
        "outputId": "91e1fc3a-a716-4ae1-ffb7-5d7614c5da2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
        "\n",
        "pred = discriminator(generated_image, training=False)\n",
        "print(pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.00264615]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAYr0lEQVR4nO2de3CV5bXGn2UADRcNCAQSQC7lJnIR\nUnus1fF2iqhUkZZqW8fjDZS22tqx2p7WOu1MC8ejTi+2U0RG6vToMFUKba2AXGqdjtSAEQHFINeE\nO8hdQcg6f2TjiZr3edPssPee8z6/mUx29pO1vzdf9pO98613rWXuDiHE/39OyfcChBC5QWYXIhFk\ndiESQWYXIhFkdiESoVUuD9auXTsvKSkJ6rHMwCmnhP82ZRMLAGZG9WPHjjX72G3atGn2YwPxtX3w\nwQdBLdvz8v7771P99NNPp/qRI0eCWnFxMY09fPgw1YuKiqjOzmvsd3L8+HGqx2jdunWzY9k5A4BW\nrcK23bt3Lw4fPtzoEyYrs5vZFQB+DqAIwHR3n8K+v6SkBHfccUdQj53gtm3bBrWjR4/S2Pbt21Od\nnUAA2LVrV1CLmbWsrIzqu3fvpnrsibN9+/agFltbzHBr1qyh+qWXXkr1devWBbVzzjmHxr7++utU\n79ChA9XZee3VqxeN3b9/P9VjdO/enersj/DatWtpbOfOnYPa9OnTg1qz38abWRGAxwCMAXA2gBvM\n7OzmPp4Q4uSSzf/s5wFY6+7r3P0ogGcAXNMyyxJCtDTZmL0cwOYGX9dk7vsIZjbRzCrNrPLQoUNZ\nHE4IkQ0n/Wq8u09z9wp3r2jXrt3JPpwQIkA2Zq8F0LPB1z0y9wkhCpBszP4qgP5m1sfM2gC4HsDc\nllmWEKKlaXbqzd2Pmdk3AMxDfepthruvYjFmRlNcsfQZS7116tSJxsbyxVu2bKH6+vXrg1q/fv1o\n7J49e6jesWNHqtfW8jdM3bp1C2rl5Z+4jPIRqqqqqD5o0CCqx847Szuyc9qUY7/33ntUZ7n0gwcP\n0tiY3qVLF6rH/mWtqalpdiw7pyxNm1We3d2fB/B8No8hhMgN2i4rRCLI7EIkgswuRCLI7EIkgswu\nRCLI7EIkQk7r2evq6miNcqwUlJVrslJKANixYwfVR44c2exjn3HGGTSW5cGBeG31kiVLqN61a9eg\nFisbjh176NChVI+VgrK8byyP/vLLL1N93759VB83blxQe+utt2jsqFGjqB4rHe7duzfV2XN9zpw5\nNJb9zljvA72yC5EIMrsQiSCzC5EIMrsQiSCzC5EIMrsQiZDT1FurVq1oZ8xYiStLccVSSKeeemp0\nbYzBgwcHtZ07d9LYRYsWUZ2dEyCeBmJdVllXXCCe7ox15Y2l9v785z8HtVgb6s9+9rNU37x5M9U3\nbNgQ1GLdX2Pp0lg6NFa+27Nnz6A2YcIEGsvS1+x5rFd2IRJBZhciEWR2IRJBZhciEWR2IRJBZhci\nEWR2IRIh53l21oL3xRdfpPEslz5w4EAaG8t7Llu2jOrDhg0LarFW0bfeeivVf/KTn1B9wIABVGfn\ndO/evTQ21gr6rrvuovovf/lLqrN8dayEdd68eVT/1a9+RXWWZ589ezaNjY0q+9rXvkb1GTNmUJ21\n+I61se7bt29QY+vWK7sQiSCzC5EIMrsQiSCzC5EIMrsQiSCzC5EIMrsQiWDunrODdevWzW+66aag\nHqsxrqysDGrDhw+nsSUlJVSP5TZZzTirLwaA0tJSqsfGSVdXV1P9wgsvDGqvvvoqja2rq6P67t27\nqX7aaadR/brrrgtq8+fPp7GsDTUQ73/A9hDEHvuVV16henFxMdVHjx5N9U2bNgW1WFv0Xr16BbVH\nHnkEmzdvbrSfdFabasxsA4ADAI4DOObuFdk8nhDi5NESO+gucXfeDkUIkXf0P7sQiZCt2R3AfDNb\nZmYTG/sGM5toZpVmVvnee+9leTghRHPJ9m3859y91sy6AlhgZm+5+0sNv8HdpwGYBtRfoMvyeEKI\nZpLVK7u712Y+7wAwG8B5LbEoIUTL02yzm1k7M+tw4jaAzwNY2VILE0K0LNm8jS8FMDszIrYVgP9x\n9xdYQF1dHa23jdVes5ry2EjmWJ49ljdlPcpj9eyxY48fP57qb7/9NtWnT58e1GK92W+55RaqP/DA\nA1SP5ZMfeuihoMZy8EA837xlyxaq33HHHUHtySefpLGxnvXt2rWjemx/A9t7wXrKA3yPABvZ3Gyz\nu/s6AHwnixCiYFDqTYhEkNmFSASZXYhEkNmFSASZXYhEyGkr6eLiYgwZMiSox8Ymx9IdjNhW3a1b\nt1KdlZH+85//pLFVVVVUP+UU/jeXjaoGeJpo1apVNHbKlClU/9KXvkT1Y8eOUb1Hjx5BLVaiOnny\nZKo/+uijVGfnnZUsA/Ex2u+++y7VY2lFlpqrqODFozU1NUGNpeX0yi5EIsjsQiSCzC5EIsjsQiSC\nzC5EIsjsQiSCzC5EIuQ0z+7uNC975MiRZj/2X/7yF6rH2j3fdtttVF+xYkVQGzFiBI298cYbqR7L\nZcf2COzbty+otW3blsbGSmA3btxIdZZHB4DBgwcHtccff5zGxkY6jxkzhuq33357UPvZz35GY9kY\nbAD405/+RPXnnnuO6pdffnlQi7XnZo/N8v96ZRciEWR2IRJBZhciEWR2IRJBZhciEWR2IRJBZhci\nEXI6srlHjx5+9913B/Xjx4/T+H79+gW12Mjl2GjipUuXUr13795BLTZqun379lRnOXwgngvftSs8\nVzM2mjiW092/fz/VYz0I2Hlbv349jR01ahTVY6Ou2YjvWHvuQYMGUT32c8f2N3zmM58Jag8//DCN\nZbXyU6dOxcaNGxvtJ61XdiESQWYXIhFkdiESQWYXIhFkdiESQWYXIhFkdiESIaf17K1bt0bXrl2D\n+rx582g8y12Wl5fT2Fi9eywXfv755we12KjpWD451jee5YsBvrZYf/PYqOszzzyT6ixfDPC+8tde\ney2Nja3tmWeeofrNN98c1GK/s1iOf9asWVR/5ZVXqM5mDcT6G6xevTqosb0H0Vd2M5thZjvMbGWD\n+zqZ2QIzq8587hh7HCFEfmnK2/gnAVzxsfvuB7DQ3fsDWJj5WghRwETN7u4vAdjzsbuvATAzc3sm\nAP5+TAiRd5p7ga7U3U8MR9sGoDT0jWY20cwqzazywIEDzTycECJbsr4a7/WVNMFqGnef5u4V7l4R\nG6YnhDh5NNfs282sOwBkPvPLpkKIvNNcs88FcFPm9k0A5rTMcoQQJ4tont3MngZwMYDOZlYD4EcA\npgCYZWa3AtgIYEJTDlZXV0d7w1999dU0ntV1L1myhMYeOnSI6v3796c66xM+cuRIGvvaa69RfeDA\ngVQfO3Ys1S+77LKg9sQTT9DYbGbeA0CfPn2o/sc//jGoxWrKY738r7rqKqpPnTo1qA0dOpTGLl++\nnOrDhg2jeizPzojVypeWBi+R0dio2d39hoAUfoYJIQoObZcVIhFkdiESQWYXIhFkdiESQWYXIhFy\nWuJqZigqKgrqa9asofHz588Patdffz2NPfvss6keG//7hS98Iajt2fPx0oGPsmDBAqqzMlCAp1oA\nYOXKlUEt1m65uLiY6rGWyl/96lepvmnTpqA2btw4GvvTn/6U6uPHj6c6a2MdG4MdS8W+8847VF+0\naBHVr7zyyqAWa0O9bdu2oMaeS3plFyIRZHYhEkFmFyIRZHYhEkFmFyIRZHYhEkFmFyIRcjqyuays\nzCdNmhTUY+2ge/XqFdQWL15MY1lpLRBvifzCCy8EtVgePNYqmo2iBuJtsFlL5r/+9a80NpZPrqmp\noXqs1POss84Kahs3bqSxq1atovoll1xC9ZKSkqBWW1tLY2OjqmNjui+88EKq//3vfw9qzz//PI39\n8pe/HNTuueceVFdXa2SzECkjswuRCDK7EIkgswuRCDK7EIkgswuRCDK7EImQ0zx7p06d/PLLLw/q\nffv2pfEDBgwIaqzNNBBvDRxrY83qn1krZwB44IEHqB4bTRzbA7B58+ag1qNHDxr7t7/9jeq33HIL\n1WP7G44fPx7UysrKaOzRo0ep/o9//IPqFRUVQY2NuQaA6dOnU33fvn1Uj7W5Zj0Qtm7dGtRix547\ndy527dqlPLsQKSOzC5EIMrsQiSCzC5EIMrsQiSCzC5EIMrsQiZDTvvEdOnTAxRdfHNRjvbxZPjnW\na/vw4cNUj9V9M7Zv3071119/neoXXHAB1T/96U9TndXqx/YufPDBB1SP5bpjOqvFnzFjBo0dPnw4\n1WP7G3bt2hXUYjXjsTkDsVHVO3fupDrr5z9ixAgay8ZBs94J0Vd2M5thZjvMbGWD+x40s1ozq8p8\nhDveCyEKgqa8jX8SwBWN3P+ou4/IfPA/k0KIvBM1u7u/BIDPNxJCFDzZXKD7hpmtyLzN7xj6JjOb\naGaVZlZ58ODBLA4nhMiG5pr9NwD6ARgBYCuAh0Pf6O7T3L3C3Svat2/fzMMJIbKlWWZ39+3uftzd\n6wA8DuC8ll2WEKKlaZbZzaxhH91xAMIzg4UQBUE0z25mTwO4GEBnM6sB8CMAF5vZCAAOYAOAcDP4\nBhQVFdG681g+mhHr0x2b9f3FL36R6q1btw5qsf7nQ4YMoTqbtw0ATz31FNVZnv7ee++lsZMnT6Y6\n628O8Ln1APD0008HtcrKShob2/swb948qnfp0iWofeUrX6Gxsefia6+9RvXY/ga2d2Lo0KE0lv3c\nrH9A1OzufkMjdz8RixNCFBbaLitEIsjsQiSCzC5EIsjsQiSCzC5EIuS0lXTPnj3929/+dlBnI3YB\ngG23/dSnPkVj6+rqqF5dXU31DRs2BLWioiIaGythfemll6geK/1laR7WshgAevfuTfVYm+tY+qxb\nt25BLVbKuXTpUqqPHj2a6qx9eCw19txzz1H90ksvpXrnzp2pzkqLY62kWdru3nvvxdq1a9VKWoiU\nkdmFSASZXYhEkNmFSASZXYhEkNmFSASZXYhEyGkr6bq6OtrSuU2bNjR+/fr1QS1WRhorh4y1Bh4/\nfnxQe+GFF2hs7OdiY6wBYNasWVRnufDvfe97NPa+++6j+hVXNNZr9P/o2rUr1Vk+edGiRTT23Xff\npfrevXupvnr16qC2ciVvwTB27Fiqx0qiv/nNb1L9zjvvDGqx1uTs983Ot17ZhUgEmV2IRJDZhUgE\nmV2IRJDZhUgEmV2IRJDZhUiEgsqzDxo0iMafddZZQW3hwoU0NpZHj9VOn3/++UHtjDPOoLGxSThz\n586l+nXXXUd1NsJ35syZNHbMmDFUj40eNmu0dPpD1qxZE9RiP1dZWRnVV61aRfXi4uKgxn6fAO+d\nAMTPa2zkc1VVVVCLjdF+4403ghrrfaBXdiESQWYXIhFkdiESQWYXIhFkdiESQWYXIhFkdiESIad5\ndnenOUSWewSAZcuWBbUf/vCHNDbWBzzWd/7cc88NamwsMcDr8AHg5ptvpjrbmwDwEb+xWvsnnuAD\neceNG0f1WC3+ihUrgtqDDz5IY2N95WNjk++6666gFhuzzUaLA/F9G88++yzVzzvvvKAW6/XP9jaw\nORDRV3Yz62lmi81stZmtMrO7M/d3MrMFZlad+dwx9lhCiPzRlLfxxwB8x93PBvBvAL5uZmcDuB/A\nQnfvD2Bh5mshRIESNbu7b3X35ZnbBwC8CaAcwDUATuwZnAng2pO1SCFE9vxLF+jMrDeAcwEsBVDq\n7ieGUm0DUBqImWhmlWZWGfvfUwhx8miy2c2sPYBnAXzL3fc31Lz+qkCjVwbcfZq7V7h7Rdu2bbNa\nrBCi+TTJ7GbWGvVG/727n7isvd3Mumf07gD4uE8hRF6Jjmy2+uv8MwHscfdvNbj/IQC73X2Kmd0P\noJO7f5c9VllZmd92221BnY33Bfh44J49e9LY0tJG/8v4kE2bNlGdlVPGSnNjI5dj73i6dOnS7Md/\n6623aGysFXRs1HWs7fHAgQOD2ttvv01jY2vr1asX1dlzO/bYsfbfNTU1VF+3bh3VBwwYENRiZcPs\n9/3YY4+hpqam0QdoSp79AgA3AnjDzE4kwr8PYAqAWWZ2K4CNACY04bGEEHkianZ3fxlA6E/NZS27\nHCHEyULbZYVIBJldiESQ2YVIBJldiESQ2YVIhJyWuLZu3Ro9evQI6rERvUxnJYNAvGywpKSE6ldf\nfXVQO378OI2NtQbetWsX1X/xi19QnbWyjp2X2LGPHDlC9c2bN1O9U6dOQe2iiy6ise3ataN6LMf/\nzjvvBLXRo0fT2MWLF1N90qRJVH/44Yep/oc//CGoffe7dLsK/bmLioqCml7ZhUgEmV2IRJDZhUgE\nmV2IRJDZhUgEmV2IRJDZhUiEnObZzYzW6sbaVl111VVB7cCBAzQ2Nv43Vt/M6pNjI5ljbNmyheo/\n/vGPqT579uygFqvzZ2OwgXhdd6xW/9RTTw1qtbW1NJbl6AGgb9++VGe1+FOmTKGxsTbXv/71r6ke\n61HA2ofHnovsua48uxBCZhciFWR2IRJBZhciEWR2IRJBZhciEWR2IRIhp3n2uro6mpdt1Yovh/Xq\nHjJkCI3dunUr1WP54oULFwa14uJiGhur+Z46dSrVly9fTvVRo0YFtd/+9rc09p577qF6bH9C7Gdn\nefwlS5bQ2Fi//Ng4arZvIzbC+80336R67Lzcfz+fczp58uSgdvToURrLcumst4Je2YVIBJldiESQ\n2YVIBJldiESQ2YVIBJldiESQ2YVIhKbMZ+8J4HcASgE4gGnu/nMzexDA7QB2Zr71++7+PHus8vJy\nv/POO4N6rHc7yz/G+p/36dOH6mvXrqU6y9n269ePxsbqk6uqqqg+YQKfhs1yxrFa+969e1N9zpw5\nWcV37tw5qJ1++uk0NjYDvbS0lOqsT8DevXtpLNu7AAD79u2j+vvvv091Vmu/bNkyGjt8+PCgNm3a\nNGzZsqXZ89mPAfiOuy83sw4AlpnZgoz2qLv/dxMeQwiRZ5oyn30rgK2Z2wfM7E0A5Sd7YUKIluVf\n+p/dzHoDOBfA0sxd3zCzFWY2w8w6BmImmlmlmVUeOnQoq8UKIZpPk81uZu0BPAvgW+6+H8BvAPQD\nMAL1r/yNDrdy92nuXuHuFbHZXUKIk0eTzG5mrVFv9N+7+3MA4O7b3f24u9cBeBwAnyAohMgrUbNb\nfTvYJwC86e6PNLi/e4NvGwdgZcsvTwjRUjTlavwFAG4E8IaZncgRfR/ADWY2AvXpuA0A+Axb1Kcb\nDh48GNR37twZ1ACemhs8eDCNjZXPxsYun3baaUGNtccG4imkWNovliZia48de9iwYVSPpRUvueQS\nqv/gBz8IamPHjqWxsZTk7bffTnWWFly0aBGNZaPFAT4OGoi3Nh85cmRQ27ZtG40tLw9fH2etv5ty\nNf5lAI09m2lOXQhRWGgHnRCJILMLkQgyuxCJILMLkQgyuxCJILMLkQjREteWpLy83CdNCqfjYyWP\nLIcYG/cc+zlj5ZKsvDaWJ4+1Bu7fvz/Vly5dSnW2x4DtDwDi52X37t1Uj+Wj2R6E6upqGltRUUH1\nWBtrxp49e6geK1Fl7ZwBYPv27VRnufTYuGe23+Sxxx5DbW1toyddr+xCJILMLkQiyOxCJILMLkQi\nyOxCJILMLkQiyOxCJEJO8+xmthPAxgZ3dQbAe0Dnj0JdW6GuC9DamktLru0sd2901nVOzf6Jg5tV\nujvfOZEnCnVthbouQGtrLrlam97GC5EIMrsQiZBvs0/L8/EZhbq2Ql0XoLU1l5ysLa//swshcke+\nX9mFEDlCZhciEfJidjO7wszWmNlaM7s/H2sIYWYbzOwNM6sys8o8r2WGme0ws5UN7utkZgvMrDrz\nudEZe3la24NmVps5d1VmdmWe1tbTzBab2WozW2Vmd2fuz+u5I+vKyXnL+f/sZlYE4G0A/w6gBsCr\nAG5w99U5XUgAM9sAoMLd874Bw8wuAnAQwO/c/ZzMff8FYI+7T8n8oezo7vcVyNoeBHAw32O8M9OK\nujccMw7gWgD/gTyeO7KuCcjBecvHK/t5ANa6+zp3PwrgGQDX5GEdBY+7vwTg4y1VrgEwM3N7Juqf\nLDknsLaCwN23uvvyzO0DAE6MGc/ruSPrygn5MHs5gM0Nvq5BYc17dwDzzWyZmU3M92IaodTdt2Zu\nbwPA+2nlnugY71zysTHjBXPumjP+PFt0ge6TfM7dRwIYA+DrmberBYnX/w9WSLnTJo3xzhWNjBn/\nkHyeu+aOP8+WfJi9FkDPBl/3yNxXELh7bebzDgCzUXijqLefmKCb+bwjz+v5kEIa493YmHEUwLnL\n5/jzfJj9VQD9zayPmbUBcD2AuXlYxycws3aZCycws3YAPo/CG0U9F8BNmds3AZiTx7V8hEIZ4x0a\nM448n7u8jz9395x/ALgS9Vfk3wHwn/lYQ2BdfQG8nvlYle+1AXga9W/rPkD9tY1bAZwJYCGAagAv\nAuhUQGt7CsAbAFag3ljd87S2z6H+LfoKAFWZjyvzfe7IunJy3rRdVohE0AU6IRJBZhciEWR2IRJB\nZhciEWR2IRJBZhciEWR2IRLhfwF843gYJbHTRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8b2o7ETFS_f",
        "colab_type": "text"
      },
      "source": [
        "## DEFINE LOSS, AND DEFINE OPTIMIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Digd3_VSFXVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer     = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0E7hj3IvGN",
        "colab_type": "text"
      },
      "source": [
        "# SETUP TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrF9uKxfIzXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images, noise_dim=100):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def train_OLD(num_epochs=100, batch_size=64):\n",
        "  generator = make_generator_model()\n",
        "  discriminator = make_discriminator_model()\n",
        "\n",
        "  gen_loss_epochs = []\n",
        "  disc_loss_epochs = []\n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    train_batches = train_dataset.shuffle(100).batch(batch_size)\n",
        "    \n",
        "    gens = []\n",
        "    discs = []\n",
        "    for sampleImages in train_batches:\n",
        "      gen_loss, disc_loss = train_step(generator, discriminator, sampleImages)\n",
        "\n",
        "      gen = gen_loss.numpy().mean()\n",
        "      disc = disc_loss.numpy().mean()\n",
        "      gens.append(gen)\n",
        "      discs.append(disc)\n",
        "    print(f'On epoch {epoch} the generator loss is {np.mean(gens):.2f}, the discriminator loss is {np.mean(discs):.2f}')\n",
        "    gen_loss_epochs.append(np.mean(gens))\n",
        "    disc_loss_epochs.append(np.mean(discs))\n",
        "  return gen_loss_epochs, disc_loss_epochs, generator, discriminator\n",
        "\n",
        "def train(dataset, num_epochs):\n",
        "  gen_loss_epochs = []\n",
        "  disc_loss_epochs = []\n",
        "\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    gens = []\n",
        "    discs = []\n",
        "    for image_batch in dataset:\n",
        "      gen_loss, disc_loss = train_step(image_batch)\n",
        "      gen = gen_loss.numpy().mean()\n",
        "      disc = disc_loss.numpy().mean()\n",
        "      gens.append(gen)\n",
        "      discs.append(disc)\n",
        "\n",
        "    print(f'On epoch {epoch} the generator loss is {np.mean(gens):.2f}, the discriminator loss is {np.mean(discs):.2f}')\n",
        "    gen_loss_epochs.append(np.mean(gens))\n",
        "    disc_loss_epochs.append(np.mean(discs))\n",
        "\n",
        "  return gen_loss_epochs, disc_loss_epochs, generator, discriminator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eMYMQYDSLN2",
        "colab_type": "code",
        "outputId": "20145347-861e-4fb1-a02d-7c5d806bd589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 200\n",
        "gen_loss, disc_loss, generator, discriminator = train(train_dataset, num_epochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "On epoch 0 the generator loss is 0.99, the discriminator loss is 0.87\n",
            "On epoch 1 the generator loss is 0.91, the discriminator loss is 1.20\n",
            "On epoch 2 the generator loss is 0.90, the discriminator loss is 1.17\n",
            "On epoch 3 the generator loss is 0.85, the discriminator loss is 1.28\n",
            "On epoch 4 the generator loss is 0.83, the discriminator loss is 1.30\n",
            "On epoch 5 the generator loss is 0.89, the discriminator loss is 1.25\n",
            "On epoch 6 the generator loss is 0.89, the discriminator loss is 1.25\n",
            "On epoch 7 the generator loss is 0.98, the discriminator loss is 1.18\n",
            "On epoch 8 the generator loss is 0.98, the discriminator loss is 1.14\n",
            "On epoch 9 the generator loss is 1.04, the discriminator loss is 1.13\n",
            "On epoch 10 the generator loss is 1.01, the discriminator loss is 1.15\n",
            "On epoch 11 the generator loss is 1.08, the discriminator loss is 1.10\n",
            "On epoch 12 the generator loss is 1.14, the discriminator loss is 1.00\n",
            "On epoch 13 the generator loss is 1.19, the discriminator loss is 1.03\n",
            "On epoch 14 the generator loss is 1.30, the discriminator loss is 0.94\n",
            "On epoch 15 the generator loss is 1.37, the discriminator loss is 0.89\n",
            "On epoch 16 the generator loss is 1.39, the discriminator loss is 0.86\n",
            "On epoch 17 the generator loss is 1.46, the discriminator loss is 0.87\n",
            "On epoch 18 the generator loss is 1.50, the discriminator loss is 0.87\n",
            "On epoch 19 the generator loss is 1.59, the discriminator loss is 0.82\n",
            "On epoch 20 the generator loss is 1.55, the discriminator loss is 0.89\n",
            "On epoch 21 the generator loss is 1.47, the discriminator loss is 0.87\n",
            "On epoch 22 the generator loss is 1.49, the discriminator loss is 0.86\n",
            "On epoch 23 the generator loss is 1.52, the discriminator loss is 0.87\n",
            "On epoch 24 the generator loss is 1.50, the discriminator loss is 0.88\n",
            "On epoch 25 the generator loss is 1.54, the discriminator loss is 0.86\n",
            "On epoch 26 the generator loss is 1.52, the discriminator loss is 0.87\n",
            "On epoch 27 the generator loss is 1.55, the discriminator loss is 0.86\n",
            "On epoch 28 the generator loss is 1.73, the discriminator loss is 0.79\n",
            "On epoch 29 the generator loss is 1.58, the discriminator loss is 0.85\n",
            "On epoch 30 the generator loss is 1.43, the discriminator loss is 0.95\n",
            "On epoch 31 the generator loss is 1.52, the discriminator loss is 0.88\n",
            "On epoch 32 the generator loss is 1.42, the discriminator loss is 0.93\n",
            "On epoch 33 the generator loss is 1.49, the discriminator loss is 0.88\n",
            "On epoch 34 the generator loss is 1.45, the discriminator loss is 0.92\n",
            "On epoch 35 the generator loss is 1.41, the discriminator loss is 0.95\n",
            "On epoch 36 the generator loss is 1.41, the discriminator loss is 0.94\n",
            "On epoch 37 the generator loss is 1.43, the discriminator loss is 0.98\n",
            "On epoch 38 the generator loss is 1.42, the discriminator loss is 0.96\n",
            "On epoch 39 the generator loss is 1.42, the discriminator loss is 0.97\n",
            "On epoch 40 the generator loss is 1.34, the discriminator loss is 1.01\n",
            "On epoch 41 the generator loss is 1.44, the discriminator loss is 0.95\n",
            "On epoch 42 the generator loss is 1.44, the discriminator loss is 0.93\n",
            "On epoch 43 the generator loss is 1.31, the discriminator loss is 1.01\n",
            "On epoch 44 the generator loss is 1.34, the discriminator loss is 1.01\n",
            "On epoch 45 the generator loss is 1.30, the discriminator loss is 1.02\n",
            "On epoch 46 the generator loss is 1.29, the discriminator loss is 1.01\n",
            "On epoch 47 the generator loss is 1.39, the discriminator loss is 0.96\n",
            "On epoch 48 the generator loss is 1.42, the discriminator loss is 0.95\n",
            "On epoch 49 the generator loss is 1.30, the discriminator loss is 1.03\n",
            "On epoch 50 the generator loss is 1.28, the discriminator loss is 1.05\n",
            "On epoch 51 the generator loss is 1.29, the discriminator loss is 1.03\n",
            "On epoch 52 the generator loss is 1.32, the discriminator loss is 1.01\n",
            "On epoch 53 the generator loss is 1.27, the discriminator loss is 1.02\n",
            "On epoch 54 the generator loss is 1.29, the discriminator loss is 1.04\n",
            "On epoch 55 the generator loss is 1.29, the discriminator loss is 1.03\n",
            "On epoch 56 the generator loss is 1.26, the discriminator loss is 1.04\n",
            "On epoch 57 the generator loss is 1.36, the discriminator loss is 1.00\n",
            "On epoch 58 the generator loss is 1.35, the discriminator loss is 1.00\n",
            "On epoch 59 the generator loss is 1.33, the discriminator loss is 1.01\n",
            "On epoch 60 the generator loss is 1.30, the discriminator loss is 1.02\n",
            "On epoch 61 the generator loss is 1.27, the discriminator loss is 1.05\n",
            "On epoch 62 the generator loss is 1.27, the discriminator loss is 1.04\n",
            "On epoch 63 the generator loss is 1.23, the discriminator loss is 1.07\n",
            "On epoch 64 the generator loss is 1.24, the discriminator loss is 1.05\n",
            "On epoch 65 the generator loss is 1.23, the discriminator loss is 1.08\n",
            "On epoch 66 the generator loss is 1.23, the discriminator loss is 1.05\n",
            "On epoch 67 the generator loss is 1.29, the discriminator loss is 1.03\n",
            "On epoch 68 the generator loss is 1.24, the discriminator loss is 1.04\n",
            "On epoch 69 the generator loss is 1.19, the discriminator loss is 1.10\n",
            "On epoch 70 the generator loss is 1.17, the discriminator loss is 1.09\n",
            "On epoch 71 the generator loss is 1.22, the discriminator loss is 1.07\n",
            "On epoch 72 the generator loss is 1.26, the discriminator loss is 1.06\n",
            "On epoch 73 the generator loss is 1.17, the discriminator loss is 1.09\n",
            "On epoch 74 the generator loss is 1.18, the discriminator loss is 1.09\n",
            "On epoch 75 the generator loss is 1.15, the discriminator loss is 1.11\n",
            "On epoch 76 the generator loss is 1.14, the discriminator loss is 1.11\n",
            "On epoch 77 the generator loss is 1.19, the discriminator loss is 1.07\n",
            "On epoch 78 the generator loss is 1.20, the discriminator loss is 1.08\n",
            "On epoch 79 the generator loss is 1.20, the discriminator loss is 1.09\n",
            "On epoch 80 the generator loss is 1.23, the discriminator loss is 1.08\n",
            "On epoch 81 the generator loss is 1.22, the discriminator loss is 1.08\n",
            "On epoch 82 the generator loss is 1.12, the discriminator loss is 1.14\n",
            "On epoch 83 the generator loss is 1.09, the discriminator loss is 1.15\n",
            "On epoch 84 the generator loss is 1.10, the discriminator loss is 1.14\n",
            "On epoch 85 the generator loss is 1.12, the discriminator loss is 1.14\n",
            "On epoch 86 the generator loss is 1.17, the discriminator loss is 1.10\n",
            "On epoch 87 the generator loss is 1.12, the discriminator loss is 1.15\n",
            "On epoch 88 the generator loss is 1.10, the discriminator loss is 1.16\n",
            "On epoch 89 the generator loss is 1.05, the discriminator loss is 1.20\n",
            "On epoch 90 the generator loss is 1.06, the discriminator loss is 1.18\n",
            "On epoch 91 the generator loss is 1.06, the discriminator loss is 1.18\n",
            "On epoch 92 the generator loss is 1.06, the discriminator loss is 1.19\n",
            "On epoch 93 the generator loss is 1.05, the discriminator loss is 1.18\n",
            "On epoch 94 the generator loss is 1.04, the discriminator loss is 1.20\n",
            "On epoch 95 the generator loss is 1.07, the discriminator loss is 1.16\n",
            "On epoch 96 the generator loss is 1.12, the discriminator loss is 1.13\n",
            "On epoch 97 the generator loss is 1.10, the discriminator loss is 1.13\n",
            "On epoch 98 the generator loss is 1.04, the discriminator loss is 1.20\n",
            "On epoch 99 the generator loss is 1.02, the discriminator loss is 1.22\n",
            "On epoch 100 the generator loss is 1.04, the discriminator loss is 1.19\n",
            "On epoch 101 the generator loss is 1.04, the discriminator loss is 1.19\n",
            "On epoch 102 the generator loss is 1.03, the discriminator loss is 1.19\n",
            "On epoch 103 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 104 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 105 the generator loss is 0.99, the discriminator loss is 1.22\n",
            "On epoch 106 the generator loss is 0.99, the discriminator loss is 1.22\n",
            "On epoch 107 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 108 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 109 the generator loss is 1.05, the discriminator loss is 1.17\n",
            "On epoch 110 the generator loss is 1.00, the discriminator loss is 1.21\n",
            "On epoch 111 the generator loss is 1.00, the discriminator loss is 1.21\n",
            "On epoch 112 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 113 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 114 the generator loss is 1.00, the discriminator loss is 1.20\n",
            "On epoch 115 the generator loss is 0.99, the discriminator loss is 1.22\n",
            "On epoch 116 the generator loss is 0.99, the discriminator loss is 1.21\n",
            "On epoch 117 the generator loss is 0.99, the discriminator loss is 1.22\n",
            "On epoch 118 the generator loss is 1.01, the discriminator loss is 1.20\n",
            "On epoch 119 the generator loss is 1.03, the discriminator loss is 1.18\n",
            "On epoch 120 the generator loss is 1.00, the discriminator loss is 1.22\n",
            "On epoch 121 the generator loss is 0.98, the discriminator loss is 1.23\n",
            "On epoch 122 the generator loss is 0.97, the discriminator loss is 1.23\n",
            "On epoch 123 the generator loss is 0.98, the discriminator loss is 1.23\n",
            "On epoch 124 the generator loss is 0.98, the discriminator loss is 1.22\n",
            "On epoch 125 the generator loss is 1.00, the discriminator loss is 1.20\n",
            "On epoch 126 the generator loss is 1.03, the discriminator loss is 1.18\n",
            "On epoch 127 the generator loss is 0.98, the discriminator loss is 1.23\n",
            "On epoch 128 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 129 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 130 the generator loss is 0.99, the discriminator loss is 1.21\n",
            "On epoch 131 the generator loss is 0.96, the discriminator loss is 1.24\n",
            "On epoch 132 the generator loss is 0.97, the discriminator loss is 1.24\n",
            "On epoch 133 the generator loss is 1.06, the discriminator loss is 1.14\n",
            "On epoch 134 the generator loss is 1.23, the discriminator loss is 1.03\n",
            "On epoch 135 the generator loss is 1.06, the discriminator loss is 1.18\n",
            "On epoch 136 the generator loss is 0.98, the discriminator loss is 1.23\n",
            "On epoch 137 the generator loss is 1.03, the discriminator loss is 1.19\n",
            "On epoch 138 the generator loss is 0.98, the discriminator loss is 1.22\n",
            "On epoch 139 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 140 the generator loss is 0.95, the discriminator loss is 1.25\n",
            "On epoch 141 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 142 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 143 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 144 the generator loss is 0.98, the discriminator loss is 1.22\n",
            "On epoch 145 the generator loss is 0.98, the discriminator loss is 1.22\n",
            "On epoch 146 the generator loss is 1.01, the discriminator loss is 1.18\n",
            "On epoch 147 the generator loss is 1.03, the discriminator loss is 1.18\n",
            "On epoch 148 the generator loss is 0.98, the discriminator loss is 1.22\n",
            "On epoch 149 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 150 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 151 the generator loss is 0.98, the discriminator loss is 1.21\n",
            "On epoch 152 the generator loss is 1.00, the discriminator loss is 1.21\n",
            "On epoch 153 the generator loss is 0.98, the discriminator loss is 1.22\n",
            "On epoch 154 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 155 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 156 the generator loss is 0.95, the discriminator loss is 1.25\n",
            "On epoch 157 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 158 the generator loss is 1.00, the discriminator loss is 1.20\n",
            "On epoch 159 the generator loss is 0.97, the discriminator loss is 1.24\n",
            "On epoch 160 the generator loss is 0.95, the discriminator loss is 1.23\n",
            "On epoch 161 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 162 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 163 the generator loss is 1.09, the discriminator loss is 1.12\n",
            "On epoch 164 the generator loss is 1.23, the discriminator loss is 1.02\n",
            "On epoch 165 the generator loss is 1.03, the discriminator loss is 1.21\n",
            "On epoch 166 the generator loss is 0.96, the discriminator loss is 1.24\n",
            "On epoch 167 the generator loss is 0.97, the discriminator loss is 1.23\n",
            "On epoch 168 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 169 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 170 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 171 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 172 the generator loss is 0.95, the discriminator loss is 1.25\n",
            "On epoch 173 the generator loss is 1.05, the discriminator loss is 1.16\n",
            "On epoch 174 the generator loss is 1.14, the discriminator loss is 1.08\n",
            "On epoch 175 the generator loss is 1.12, the discriminator loss is 1.14\n",
            "On epoch 176 the generator loss is 0.97, the discriminator loss is 1.25\n",
            "On epoch 177 the generator loss is 0.95, the discriminator loss is 1.25\n",
            "On epoch 178 the generator loss is 0.95, the discriminator loss is 1.25\n",
            "On epoch 179 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 180 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 181 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 182 the generator loss is 0.97, the discriminator loss is 1.22\n",
            "On epoch 183 the generator loss is 0.99, the discriminator loss is 1.21\n",
            "On epoch 184 the generator loss is 0.96, the discriminator loss is 1.23\n",
            "On epoch 185 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 186 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 187 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 188 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 189 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 190 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 191 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 192 the generator loss is 0.95, the discriminator loss is 1.24\n",
            "On epoch 193 the generator loss is 0.97, the discriminator loss is 1.23\n",
            "On epoch 194 the generator loss is 0.94, the discriminator loss is 1.25\n",
            "On epoch 195 the generator loss is 0.92, the discriminator loss is 1.27\n",
            "On epoch 196 the generator loss is 0.92, the discriminator loss is 1.26\n",
            "On epoch 197 the generator loss is 0.92, the discriminator loss is 1.27\n",
            "On epoch 198 the generator loss is 0.94, the discriminator loss is 1.24\n",
            "On epoch 199 the generator loss is 0.99, the discriminator loss is 1.20\n",
            "On epoch 200 the generator loss is 0.93, the discriminator loss is 1.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRHfVOurEb-a",
        "colab_type": "text"
      },
      "source": [
        "Plot the loss functions for the generator and discriminator. Label them accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0FmafAMEilj",
        "colab_type": "code",
        "outputId": "b34ecf65-8199-48b7-b60d-dffb6260bc8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.figure()\n",
        "x = range(1, EPOCHS+2)\n",
        "plt.plot(x, gen_loss, x, disc_loss)\n",
        "plt.legend(['Generator Loss', 'Discriminator Loss'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4d26f40048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHleXQWiEJzc",
        "colab_type": "text"
      },
      "source": [
        "Show three example generated photos using your model. Even though the images may not be perfect, it should be perceivable as a fashion photo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjPrCCnQETs6",
        "colab_type": "code",
        "outputId": "5c3a5c15-089e-4528-d7b7-e1c732aecc3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "def plotGeneratorOutput(generator, numRows=10, numCols=10):\n",
        "  results = generator(tf.random.uniform((numRows*numCols, 100), minval = -1.0, maxval = 1.0)).numpy()\n",
        "\n",
        "  figure, axes = plt.subplots(nrows=numRows, ncols=numCols)\n",
        "  figure.set_size_inches(2*numCols, 2*numRows)\n",
        "  \n",
        "  for idx, axis in enumerate(axes.flat):\n",
        "    image = np.reshape(results[idx], (28,28))*127.5+127.5\n",
        "    \n",
        "    axis.imshow(image, cmap=plt.cm.gray)\n",
        "    axis.set_frame_on(False)\n",
        "    axis.set_axis_off()\n",
        "\n",
        "plotGeneratorOutput(generator, 1, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABwCAYAAAC9zaPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgCDWjv-Ejdy",
        "colab_type": "text"
      },
      "source": [
        "# Question 2\n",
        "Design a method to conditionally generate photos of different labels. Pick two classes within the MNIST fasion dataset, and use them to conditionally generate photos of those two classes. You will likely need to include another outcome variable in the discriminator to account for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAUhls-PHX5_",
        "colab_type": "code",
        "outputId": "6510355a-edca-4d15-e95a-2370633f14b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "conditionalLabelNum = 10\n",
        "\n",
        "#Takes in a 100+conditionalLabelNum vector\n",
        "def make_cond_generator_model():\n",
        "  model = tf.keras.Sequential(name = 'Conditional Generator')\n",
        "  model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100 + conditionalLabelNum,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((7, 7, 256)))\n",
        "  assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1, (3, 3), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model\n",
        "\n",
        "def make_cond_discriminator_model():\n",
        "  # define two sets of inputs\n",
        "  inp_images = Input(shape=(28,28,1,))\n",
        "  inp_oneHot = Input(shape=(conditionalLabelNum,))\n",
        "  print(inp_oneHot)\n",
        "  dense1 = Dense(784, activation='relu')(inp_oneHot)\n",
        "  y = Reshape((28, 28, 1))(dense1)\n",
        "\n",
        "  y = Model(inputs=inp_oneHot, outputs=y)\n",
        "  imageModel = Model(inputs=inp_images, outputs=inp_images)\n",
        "\n",
        "  #Concatenate new one hot encoding image with inputted images\n",
        "  combined = layers.concatenate([imageModel.outputs, xFormModel.outputs])\n",
        "\n",
        "  conv1 = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(combined)\n",
        "  lRelu1 = layers.LeakyReLU()(conv1)\n",
        "  drop1 = layers.Dropout(0.3)(lRelu1)\n",
        "\n",
        "  conv2 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(drop1)\n",
        "  lRelu2 = layers.LeakyReLU()(conv2)\n",
        "  drop2 = layers.Dropout(0.3)(lRelu2)\n",
        "\n",
        "  flat = layers.Flatten()(drop2)\n",
        "  prob = layers.Dense(1, input_shape=(7*7*128,))(flat)\n",
        "  print(prob)\n",
        "  print(inp_images)\n",
        "  print(inp_oneHot)\n",
        "  # This model allows us to concatenate one hot encodings to the images and then get the discriminator output\n",
        "  model = Model(inputs=[inp_images, inp_oneHot], outputs=prob, name='Conditional Discriminator')\n",
        "\n",
        "  return model\n",
        "\n",
        "#Test these\n",
        "cond_generator = make_cond_generator_model()\n",
        "print(generator.summary())\n",
        "\n",
        "cond_discriminator = make_cond_discriminator_model()\n",
        "print(discriminator.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 12544)             1254400   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTr (None, 7, 7, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTr (None, 14, 14, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTr (None, 28, 28, 1)         576       \n",
            "=================================================================\n",
            "Total params: 2,329,920\n",
            "Trainable params: 2,304,448\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n",
            "None\n",
            "Tensor(\"input_62:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-1042e60e3564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mcond_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_cond_discriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-1042e60e3564>\u001b[0m in \u001b[0;36mmake_cond_discriminator_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp_oneHot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mimageModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 237\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m                   tensor_index=tensor_index)\n\u001b[0m\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;31m# Propagate to all previous tensors connected to this node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'Dense' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPxcAy6yHYIO",
        "colab_type": "text"
      },
      "source": [
        "Plot all of your loss functions and label them accordingly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1RLNXUeHgFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxHl3i_3HgX_",
        "colab_type": "text"
      },
      "source": [
        "Show three examples of photos generated of your first class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTzqSSP5HpQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtiF9UMbHpiW",
        "colab_type": "text"
      },
      "source": [
        "Show three examples of photos generated of your second class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BImdFikeHsHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
